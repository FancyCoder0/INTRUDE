{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init nlp model with facebook/react data!\n",
      "model already exists!\n",
      "init nlp model for text successfully!\n",
      "model already exists!\n",
      "init nlp model for code successfully!\n",
      "{'title': [0.3072585887396503], 'desc': [0.4508086834858737], 'code': [1.0, 1.0], 'file_list': [1.0, 1], 'location': [0.6666666666666666, 0.6666666666666666], 'pattern': [-1]}\n",
      "Data Loading.........\n",
      "Model Data Input= /home/luyao/PR_get/INTRUDE/data/clf/first_msr_pairs.txt\n",
      "warning: feature vectore already exists! /home/luyao/PR_get/INTRUDE/data/clf/first_msr_pairs_feature_vector_ok_text_lsi_code_tfidf_ori_and_overlap\n",
      "Model Data Input= /home/luyao/PR_get/INTRUDE/data/clf/second_msr_pairs.txt\n",
      "warning: feature vectore already exists! /home/luyao/PR_get/INTRUDE/data/clf/second_msr_pairs_feature_vector_ok_text_lsi_code_tfidf_ori_and_overlap\n",
      "Model Data Input= /home/luyao/PR_get/INTRUDE/data/clf/first_nondup.txt\n",
      "warning: feature vectore already exists! /home/luyao/PR_get/INTRUDE/data/clf/first_nondup_feature_vector_ok_text_lsi_code_tfidf_ori_and_overlap\n",
      "Model Data Input= /home/luyao/PR_get/INTRUDE/data/clf/second_nondup.txt\n",
      "warning: feature vectore already exists! /home/luyao/PR_get/INTRUDE/data/clf/second_nondup_feature_vector_ok_text_lsi_code_tfidf_ori_and_overlap\n",
      "--------------------------\n",
      "Model: training_set 50618 testing_set 50737 feature_length= 9\n",
      "------ model:  boost ------\n",
      "[0.22  0.42  0.105 0.005 0.06  0.035 0.045 0.045 0.065]\n",
      "Mean Accuracy: 0.9942645406705166\n",
      "Average precision score: 0.9191\n",
      "F1 score: 0.8643\n",
      "0.6226046505860838\n"
     ]
    }
   ],
   "source": [
    "from git import *\n",
    "from comp import *\n",
    "from clf import *\n",
    "\n",
    "\n",
    "#p1=get_pull('laravel/framework','4138')\n",
    "#p2=get_pull('laravel/framework','2678')\n",
    "\n",
    "#s = 'facebook/react 3969 3807'\n",
    "\n",
    "#s = 'facebook/react 12488\t10255'\n",
    "\n",
    "#s = 'facebook/react 11868\t4426'\n",
    "\n",
    "#s='facebook/react\t12770\t12311'\n",
    "\n",
    "# s = 'elastic/elasticsearch 27744 27600'\n",
    "\n",
    "# s = 'CleverRaven/Cataclysm-DDA 10005 8445'\n",
    "\n",
    "# s = 'Homebrew/homebrew-cask\t48598\t35654'\n",
    "\n",
    "# s = 'kubernetes/kubernetes 50018 55744'\n",
    "\n",
    "s = 'facebook/react 8996 8815'\n",
    "\n",
    "repo, n1, n2 = s.split()\n",
    "\n",
    "init_model_with_repo(repo)\n",
    "\n",
    "p1=get_pull(repo, n1)\n",
    "p2=get_pull(repo, n2)\n",
    "\n",
    "#print(fetch_pr_info(p1))\n",
    "#print(fetch_pr_info(p2))\n",
    "\n",
    "# print(get_numbers(p1['body']), get_numbers(p2['body']))\n",
    "#calc_sim(p1,p2)\n",
    "\n",
    "'''\n",
    "print(p1['body'])\n",
    "print(p2['body'])\n",
    "\n",
    "A=p1\n",
    "print(get_version_numbers(A[\"title\"] + ' ' + A['body']))\n",
    "   \n",
    "A=p2\n",
    "print(get_version_numbers(A[\"title\"] + ' ' + A['body']))\n",
    "'''\n",
    "\n",
    "vet = get_pr_sim(p1,p2)\n",
    "\n",
    "print(vet)\n",
    "\n",
    "\n",
    "c = classify()\n",
    "ret = c.predict_proba([get_pr_sim_vector(p1,p2)])[0][1]\n",
    "\n",
    "print(ret)\n",
    "\n",
    "\n",
    "#print(get_topK('elastic/elasticsearch', '6287', 10, True))\n",
    "\n",
    "#print(get_topK('facebook/react', '1702', 10, True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import simulate_part_pr\n",
    "\n",
    "\n",
    "\n",
    "s = 'angular/angular.js\t8492\t8233'\n",
    "repo, n1, n2 = s.split()\n",
    "\n",
    "init_model_with_repo(repo)\n",
    "\n",
    "simulate_part_pr.simulate(repo, n1, n2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from detect import *\n",
    " \n",
    "\n",
    "print(get_topK('symfony/symfony', '10425', 10, True)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from git import *\n",
    "\n",
    "repos = open('data/msr_repo_list.txt').readlines()\n",
    "\n",
    "# repo = 'cocos2d/cocos2d-x'\n",
    "\n",
    "for repo in repos:\n",
    "\n",
    "    pulls = get_pull_list(repo, False)\n",
    "\n",
    "    num, tot = 0, 0\n",
    "    for pull in pulls:\n",
    "        tot += 1\n",
    "        if len(get_pr_numbers(str(pull['title']) + str(pull['body']))) > 0:\n",
    "            num += 1\n",
    "    print(repo.strip(), ':', 1.0 * num / tot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import *\n",
    "\n",
    "# init_model_with_repo('Ultimaker/Ultimaker2Marlin')\n",
    "init_model_with_repo('MarlinFirmware/Marlin')\n",
    "get_sim_vector(get_pull('Ultimaker/Ultimaker2Marlin', '50'), get_pull('MarlinFirmware/Marlin', '1402'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import *\n",
    "\n",
    "# init_model_with_repo('ceph/ceph')\n",
    "\n",
    "p1 = get_pull('hashicorp/terraform', '6827')\n",
    "t = get_another_pull(p1)\n",
    "print(type(t[0]))\n",
    "print(get_another_pull(p1))\n",
    "\n",
    "print(type(p1[\"number\"]))\n",
    "'''\n",
    "p2 = get_pull('ceph/ceph', '10427')\n",
    "print(get_BoW(p1[\"title\"]))\n",
    "print(get_BoW(p2[\"title\"]))\n",
    "\n",
    "print(get_sim('ceph/ceph', '10438', '10427'))\n",
    "\n",
    "print(check_pattern(p1, p2))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import *\n",
    "\n",
    "# init_model_with_repo('Ultimaker/Ultimaker2Marlin')\n",
    "init_model_with_repo('MarlinFirmware/Marlin')\n",
    "get_sim_vector(get_pull('Ultimaker/Ultimaker2Marlin', '50'), get_pull('MarlinFirmware/Marlin', '1402'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import *\n",
    "\n",
    "# init_model_with_repo('Ultimaker/Ultimaker2Marlin')\n",
    "init_model_with_repo('MarlinFirmware/Marlin')\n",
    "get_pr_sim_vector(get_pull('Ultimaker/Ultimaker2Marlin', '50'), get_pull('MarlinFirmware/Marlin', '1402'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import main\n",
    "# main.init_model_with_repo('facebook/react')\n",
    "# main.get_sim('facebook/react', '12767', '11770')\n",
    "\n",
    "main.init_model_with_repo('facebook/react')\n",
    "main.get_sim('facebook/react', '466', '433')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import main\n",
    "main.init_model_with_repo('facebook/react')\n",
    "main.get_sim('facebook/react', '12767', '11770')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import main\n",
    "import git\n",
    "\n",
    "%time main.init_model_with_pulls(git.get_pull_list('MarlinFirmware/Marlin'))\n",
    "\n",
    "'''\n",
    "import main\n",
    "main.init_model_with_repo('SignalR/SignalR')\n",
    "main.get_sim('SignalR/SignalR', '3094', '3862')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def camel_case_split(identifier):\n",
    "    matches = re.finditer('.+?(?:(?<=[a-z])(?=[A-Z])|(?<=[A-Z])(?=[A-Z][a-z])|$)', identifier)\n",
    "    return [m.group(0) for m in matches]\n",
    "\n",
    "print(camel_case_split('AasAdsaB'))\n",
    "print(camel_case_split('dasAdsaBcdas'))\n",
    "print(camel_case_split('ARM64'))\n",
    "\n",
    "print(camel_case_split('321jca+dsad321_dsaAz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import main\n",
    "c = main.classify() # all\n",
    "\n",
    "\"\"\"\n",
    "with open('tmp/1.txt') as f:\n",
    "    for l in f.readlines():\n",
    "        if len(l)<=3:\n",
    "            continue\n",
    "        p, n1, n2 = l.split()\n",
    "        \n",
    "        t = main.get_sim(p, n1, n2)\n",
    "        \n",
    "        print(c.predict([t])[0], p, n1, n2, t)\n",
    "\"\"\"\n",
    "\n",
    "with open('')\n",
    "X_test = localfile_tool.get_file('data/improve_false_data_msr_positive_pairs_lsi_X.json')\n",
    "y_test = localfile_tool.get_file('data/improve_false_data_msr_positive_pairs_lsi_y.json')\n",
    "\n",
    "acc = c.score(X_test, y_test)\n",
    "print('Mean Accuracy:', acc)\n",
    "\n",
    "# c.predict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import main\n",
    "main.get_sim('mozilla-b2g/gaia', '2420', '2459')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import main\n",
    "p = main.get_pull('mozilla-b2g/gaia', '2420')\n",
    "f = fetch_pr_info(p)\n",
    "print([x[\"name\"] for x in f])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import *\n",
    "from git import *\n",
    "from comparer import *\n",
    "\n",
    "repo = 'spring-projects/spring-framework'\n",
    "init_model_with_pulls([], repo.replace('/','_') + '_all')\n",
    "# init_model_with_repo(repo)\n",
    "\n",
    "x = 'Changed min accepted day of month to 1'\n",
    "y = 'Support for the last day in month cron expression'\n",
    "\n",
    "'''\n",
    "x = 'Tokenizer - removing unnecessary boxing'\n",
    "y = 'Tokenizer - removes unnecessary boxing of char'\n",
    "'''\n",
    "\n",
    "%timeit text_sim(x,y)\n",
    "# text_sim(x,y)\n",
    "'''\n",
    "print(model.get_tfidf(get_BoW(x)))\n",
    "print(model.get_tfidf(get_BoW(y)))\n",
    "c = set(get_BoW(x)) & set(get_BoW(y))\n",
    "print(model.get_idf_sum(c))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import localfile\n",
    "ps = localfile.get_file('data/msr_positive_pairs_feature_vector_all_clues_with_text_lsi_code_bow_X.json')\n",
    "for p in ps:\n",
    "    if p[0] >= 0.9:\n",
    "        print(p[0], p[2])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from git import *\n",
    "from comp import *\n",
    "\n",
    "def func(file):\n",
    "\n",
    "    num = 0\n",
    "    tot = 0\n",
    "    with open(file) as f:\n",
    "        for f0 in f.readlines():\n",
    "            r, n1, n2 = f0.split()\n",
    "            p1 = get_pull(r, n1)\n",
    "            p2 = get_pull(r, n2)\n",
    "            s1 = get_tokens(p1['title'])\n",
    "            s2 = get_tokens(p2['title'])\n",
    "            if (set(s1) & set(s2)):\n",
    "                t = len(s1) + len(s1)\n",
    "                num += 1\n",
    "                tot += t\n",
    "\n",
    "    print (1.0 * tot / num)\n",
    "    \n",
    "func('data/clf/small_part_negative.txt')\n",
    "func('data/clf/msr_positive_pairs.txt')\n",
    "\n",
    "                                    \n",
    "'''                      \n",
    "with open('data/clf/manual_label_false.txt') as f:\n",
    "    for t in f.readlines():\n",
    "        r, n1, n2 = t.split()\n",
    "        p1 = get_pull(r, n1)\n",
    "        p2 = get_pull(r, n2)\n",
    "        t = set(get_tokens(p1['title'])) & set(get_tokens(p2['title']))\n",
    "        if t:\n",
    "            print(t)\n",
    "'''     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from git import *\n",
    "from comp import *\n",
    "\n",
    "r = 'laravel/framework'\n",
    "\n",
    "ps = get_repo_info(r, 'pull')\n",
    "tot = 0\n",
    "cnt = 0\n",
    "for p in ps:\n",
    "    cnt += 1\n",
    "    print(cnt)\n",
    "\n",
    "    file_list = fetch_pr_info(p)\n",
    "    for file in file_list:\n",
    "        tot += len(file[\"add_code\"]) + len(file[\"del_code\"])\n",
    "\n",
    "print('tot=', tot)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from numpy import median\n",
    "from clf import *\n",
    "\n",
    "\n",
    "def q(a):\n",
    "    print('\\t'.join(['{0:0.4f}'.format(1.0 * sum(a[:,i]) / len(a)) for i in range(len(a[0]))]))\n",
    "    \n",
    "    # print('\\t'.join(['{0:0.4f}'.format(median(a[:,i])) for i in range(len(a[0]))]))\n",
    "    \n",
    "f = []\n",
    "no = []\n",
    "yes = []\n",
    "for s in dataset:\n",
    "    new_X, new_y = get_feature_vector(s[0], s[1], model_data_renew_flag, model_data_save_path_suffix)\n",
    "    \n",
    "    if ('true' in s[0]) or ('msr' in s[0]):\n",
    "        yes += new_X\n",
    "    else:\n",
    "        no += new_X\n",
    "\n",
    "no = array(no)\n",
    "yes = array(yes)\n",
    "\n",
    "# q(no)\n",
    "# q(yes)\n",
    "\n",
    "\n",
    "# sum(L) / float(len(L))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from clf import *\n",
    "from comp import *\n",
    "\n",
    "last = None\n",
    "q = []\n",
    "\n",
    "cnt = {}\n",
    "\n",
    "with open('/home/luyao/PR_get/INTRUDE/data/clf/manual_label_true.txt') as f:\n",
    "    for pair in f.readlines():\n",
    "        r, n1, n2 = pair.split()\n",
    "        \n",
    "        if r != last:\n",
    "            last = r\n",
    "            # init_model_with_repo(r)\n",
    "            print('cnt', r)\n",
    "            cnt = {}\n",
    "            ps = get_repo_info(r, 'pull')\n",
    "            for p in ps:\n",
    "                for x in get_tokens(p['title']):\n",
    "                    if x not in cnt:\n",
    "                        cnt[x] = 0\n",
    "                    cnt[x] += 1\n",
    "        \n",
    "        p1 = get_pull(r, n1)\n",
    "        p2 = get_pull(r, n2)\n",
    "        \n",
    "        def add(p):\n",
    "            x = [cnt.get(word, 0) for word in get_tokens(p['title'])]\n",
    "            q.append(sum(x) / len(x))\n",
    "            \n",
    "        add(p1)\n",
    "        add(p2)\n",
    "\n",
    "print(sum(q) / len(q))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clf import *\n",
    "from comp import *\n",
    "\n",
    "init_model_with_repo('bitcoin/bitcoin')\n",
    "p1 = get_pull('peercoin/peercoin', '219')\n",
    "p2 = get_pull('bitcoin/bitcoin', '5509')\n",
    "\n",
    "print(get_pr_sim_vector(p1, p2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "files = [\n",
    "'/home/luyao/PR_get/INTRUDE/data/clf/manual_label_false.txt',\n",
    "#'/home/luyao/PR_get/INTRUDE/data/clf/manual_label_true.txt',\n",
    "'/home/luyao/PR_get/INTRUDE/data/clf/openpr_label_false.txt',\n",
    "#'/home/luyao/PR_get/INTRUDE/data/clf/openpr_label_true.txt'\n",
    "]\n",
    "\n",
    "for file in files:\n",
    "    for t in open(file).readlines():\n",
    "        r, n1, n2 = t.split()\n",
    "        p1 = get_pull(r, n1)\n",
    "        p2 = get_pull(r, n2)\n",
    "        \n",
    "        def add(p1):\n",
    "            file_list = fetch_pr_info(p1)\n",
    "            return sum([x[\"LOC\"]['add'] for x in file_list])\n",
    "        def dele(p1):\n",
    "            file_list = fetch_pr_info(p1)\n",
    "            return sum([x[\"LOC\"]['del'] for x in file_list])\n",
    "        \n",
    "        \n",
    "        print(t.strip(), 'line=', '+%d,-%d' % (add(p1), dele(p1)) , '\\t', '+%d,-%d' % (add(p2), dele(p2)))\n",
    "        print(p1['title'])\n",
    "        print(p2['title'])\n",
    "        \n",
    "        print('------')\n",
    "    \n",
    "        '''\n",
    "        file_list = fetch_pr_info(p1)\n",
    "        if len(file_list) <= 10:\n",
    "            #print(p1['title'], ':', [x['name'] for x in file_list])\n",
    "            t = sum([x[\"LOC\"]['add'] for x in file_list])\n",
    "            if t <= 10:\n",
    "                print(r, n1, n2, p1['title'], ':', t)\n",
    "        ''' \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\n",
    "    '/home/luyao/PR_get/INTRUDE/data/clf/small_part_msr.txt',\n",
    "    '/home/luyao/PR_get/INTRUDE/data/clf/rly_false_pairs.txt'\n",
    "]\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def get_time(t):\n",
    "    return datetime.strptime(t, \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "\n",
    "from git import *\n",
    "\n",
    "for file in files:\n",
    "    q = []\n",
    "    for t in open(file).readlines():\n",
    "        r, n1, n2 = t.split()\n",
    "        p1 = get_pull(r, n1)\n",
    "        p2 = get_pull(r, n2)\n",
    "        \n",
    "        d = abs((get_time(p1['created_at']) - get_time(p2['created_at'])).days)\n",
    "        q.append(d)\n",
    "\n",
    "    print(sum(q) / len(q))\n",
    "    print(sorted(q))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from git import *\n",
    "# % timeit t = get_pull(, )\n",
    "\n",
    "% timeit t = api.get('repos/%s/pulls/%s' % ('facebook/react', '12391'))\n",
    "\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_sim_type= lsi\n",
      "code_sim_type= tfidf\n",
      "extract_sim_type= ori_and_overlap\n",
      "Data Type: ok_text_lsi_code_tfidf_ori_and_overlap\n",
      "Data Loading.........\n",
      "Model Data Input= /home/luyao/PR_get/INTRUDE/data/clf/first_msr_pairs.txt\n",
      "warning: feature vectore already exists! /home/luyao/PR_get/INTRUDE/data/clf/first_msr_pairs_feature_vector_ok_text_lsi_code_tfidf_ori_and_overlap\n",
      "Model Data Input= /home/luyao/PR_get/INTRUDE/data/clf/second_msr_pairs.txt\n",
      "warning: feature vectore already exists! /home/luyao/PR_get/INTRUDE/data/clf/second_msr_pairs_feature_vector_ok_text_lsi_code_tfidf_ori_and_overlap\n",
      "Model Data Input= /home/luyao/PR_get/INTRUDE/data/clf/first_nondup.txt\n",
      "warning: feature vectore already exists! /home/luyao/PR_get/INTRUDE/data/clf/first_nondup_feature_vector_ok_text_lsi_code_tfidf_ori_and_overlap\n",
      "Model Data Input= /home/luyao/PR_get/INTRUDE/data/clf/second_nondup.txt\n",
      "warning: feature vectore already exists! /home/luyao/PR_get/INTRUDE/data/clf/second_nondup_feature_vector_ok_text_lsi_code_tfidf_ori_and_overlap\n",
      "--------------------------\n",
      "Model: training_set 50618 testing_set 50737 feature_length= 9\n",
      "------ model:  boost ------\n",
      "[0.22  0.42  0.105 0.005 0.05  0.045 0.035 0.055 0.065]\n",
      "Mean Accuracy: 0.9942645406705166\n",
      "Average precision score: 0.9191\n",
      "F1 score: 0.8643\n",
      "init nlp model with laravel/framework data!\n",
      "model already exists!\n",
      "init nlp model for text successfully!\n",
      "model already exists!\n",
      "init nlp model for code successfully!\n",
      "progress =  0.1305293691080493\n",
      "progress =  0.22480058013052936\n",
      "progress =  0.39158810732414795\n",
      "progress =  0.43509789702683105\n",
      "progress =  0.580130529369108\n",
      "progress =  0.6816533720087019\n",
      "progress =  0.7034082668600435\n",
      "progress =  0.7831762146482959\n",
      "[(16655, 0.6029130227943807), (16018, 0.6029130227943807), (15593, 0.5880381771736395), (17451, 0.5747332692442766), (15661, 0.5547340525839011), (16170, 0.5314063964295124), (16867, 0.5218326721905272), (14710, 0.48754458267015777), (13817, 0.48754458267015777), (19708, 0.48504067368337705)]\n"
     ]
    }
   ],
   "source": [
    "from detect import *\n",
    "print(get_topK('laravel/framework', '22057', 10, True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init nlp model with laravel/framework data!\n",
      "model already exists!\n",
      "init nlp model for text successfully!\n",
      "model already exists!\n",
      "init nlp model for code successfully!\n",
      "{'title': [0.8746197528924626], 'desc': [0.0], 'code': [0.6404730300257933, 0.6404730300257933], 'file_list': [1.0, 1], 'location': [0.0, 0.0], 'pattern': [0]}\n",
      "Data Loading.........\n",
      "Model Data Input= /home/luyao/PR_get/INTRUDE/data/clf/first_msr_pairs.txt\n",
      "warning: feature vectore already exists! /home/luyao/PR_get/INTRUDE/data/clf/first_msr_pairs_feature_vector_ok_text_lsi_code_tfidf_ori_and_overlap\n",
      "Model Data Input= /home/luyao/PR_get/INTRUDE/data/clf/second_msr_pairs.txt\n",
      "warning: feature vectore already exists! /home/luyao/PR_get/INTRUDE/data/clf/second_msr_pairs_feature_vector_ok_text_lsi_code_tfidf_ori_and_overlap\n",
      "Model Data Input= /home/luyao/PR_get/INTRUDE/data/clf/first_nondup.txt\n",
      "warning: feature vectore already exists! /home/luyao/PR_get/INTRUDE/data/clf/first_nondup_feature_vector_ok_text_lsi_code_tfidf_ori_and_overlap\n",
      "Model Data Input= /home/luyao/PR_get/INTRUDE/data/clf/second_nondup.txt\n",
      "warning: feature vectore already exists! /home/luyao/PR_get/INTRUDE/data/clf/second_nondup_feature_vector_ok_text_lsi_code_tfidf_ori_and_overlap\n",
      "--------------------------\n",
      "Model: training_set 50618 testing_set 50737 feature_length= 9\n",
      "------ model:  boost ------\n",
      "[0.22  0.42  0.105 0.005 0.045 0.05  0.035 0.055 0.065]\n",
      "Mean Accuracy: 0.9942645406705166\n",
      "Average precision score: 0.9191\n",
      "F1 score: 0.8643\n",
      "0.5601423492316505\n"
     ]
    }
   ],
   "source": [
    "from git import *\n",
    "from comp import *\n",
    "from clf import *\n",
    "\n",
    "s = 'laravel/framework 18705 17589'\n",
    "\n",
    "repo, n1, n2 = s.split()\n",
    "\n",
    "init_model_with_repo(repo)\n",
    "\n",
    "p1=get_pull(repo, n1)\n",
    "p2=get_pull(repo, n2)\n",
    "\n",
    "vet = get_pr_sim(p1,p2)\n",
    "\n",
    "print(vet)\n",
    "\n",
    "c = classify()\n",
    "ret = c.predict_proba([get_pr_sim_vector(p1,p2)])[0][1]\n",
    "\n",
    "print(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
