{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from comp import *\n",
    "from git import *\n",
    "from clf import *\n",
    "\n",
    "files = [\n",
    "'/home/luyao/PR_get/INTRUDE/data/clf/manual_label_false.txt',\n",
    "#'/home/luyao/PR_get/INTRUDE/data/clf/manual_label_true.txt',\n",
    "'/home/luyao/PR_get/INTRUDE/data/clf/openpr_label_false.txt',\n",
    "#'/home/luyao/PR_get/INTRUDE/data/clf/openpr_label_true.txt'\n",
    "]\n",
    "\n",
    "num1, num2 = 0, 0\n",
    "\n",
    "def hasNumbers(inputString):\n",
    "    return any(char.isdigit() for char in inputString)\n",
    "\n",
    "def check_meaningless(title):\n",
    "    title = title.lower()\n",
    "    if 'revert' in title:\n",
    "        return True\n",
    "    if 'typo' in title:\n",
    "        return True\n",
    "    if (('updat' in title) or ('upgrade' in title)) and ('to' in title.split(' ')) and (get_version_numbers(title)):\n",
    "        return True\n",
    "    if (('updat' in title) or ('upgrade' in title)) and (('version' in title) or ('doc' in title)):\n",
    "        return True\n",
    "    if 'readme' in title:\n",
    "        return True\n",
    "    if 'changelog' in title:\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "for file in files:\n",
    "    for t in open(file).readlines():\n",
    "        r, n1, n2 = t.split()\n",
    "        p1 = get_pull(r, n1)\n",
    "        p2 = get_pull(r, n2)\n",
    "        \n",
    "        def add(p1):\n",
    "            file_list = fetch_pr_info(p1)\n",
    "            return sum([x[\"LOC\"]['add'] for x in file_list])\n",
    "        def dele(p1):\n",
    "            file_list = fetch_pr_info(p1)\n",
    "            return sum([x[\"LOC\"]['del'] for x in file_list])\n",
    "        \n",
    "        \n",
    "        \n",
    "        '''\n",
    "        if check_meaningless(p1['title']) or check_meaningless(p2['title']):\n",
    "            pass\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "        init_model_with_repo(r)\n",
    "        \n",
    "        if ret['code'][0] >= 0.6:\n",
    "            continue\n",
    "        '''\n",
    "            \n",
    "        # ret = get_pr_sim(p1, p2)\n",
    "        \n",
    "        '''\n",
    "        if ret['pattern'][0] == 1:\n",
    "            continue\n",
    "        '''\n",
    "        \n",
    "        if (check_meaningless(p1['title']) or check_meaningless(p2['title'])) and (check_pattern(p1, p2) != 1):\n",
    "            \n",
    "            num1 += 1\n",
    "            \n",
    "        else:\n",
    "            num2 +=1 \n",
    "            continue\n",
    "        \n",
    "        print(check_meaningless(p1['title']), check_meaningless(p2['title']), p1['merged_at'], p2['merged_at'])\n",
    "        \n",
    "        print(t.strip(), 'line=', '+%d,-%d' % (add(p1), dele(p1)) , '\\t', '+%d,-%d' % (add(p2), dele(p2)))\n",
    "        print(p1['title'])\n",
    "        print(p2['title'])\n",
    "        \n",
    "        # print(ret)\n",
    "        try:\n",
    "            print('pattern', check_pattern(p1, p2))\n",
    "        except:\n",
    "            pass\n",
    "        print('------')\n",
    "        \n",
    "        \n",
    "    \n",
    "        '''\n",
    "        file_list = fetch_pr_info(p1)\n",
    "        if len(file_list) <= 10:\n",
    "            #print(p1['title'], ':', [x['name'] for x in file_list])\n",
    "            t = sum([x[\"LOC\"]['add'] for x in file_list])\n",
    "            if t <= 10:\n",
    "                print(r, n1, n2, p1['title'], ':', t)\n",
    "        ''' \n",
    "\n",
    "print(num1, num2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from comp import *\n",
    "from git import *\n",
    "from clf import *\n",
    "\n",
    "num, tot = 0, 0\n",
    "\n",
    "#file = 'data/clf/msr_positive_pairs.txt'\n",
    "# file = '/home/luyao/PR_get/INTRUDE/data/clf/manual_label_false.txt'\n",
    "file = '/home/luyao/PR_get/INTRUDE/data/clf/manual_label_true.txt'\n",
    "\n",
    "\n",
    "for t in open(file).readlines():\n",
    "    tot += 1\n",
    "\n",
    "    r, n1, n2 = t.split()\n",
    "    p1 = get_pull(r, n1)\n",
    "    p2 = get_pull(r, n2)\n",
    "    \n",
    "    file_list1 = fetch_pr_info(p1)\n",
    "    file_list2 = fetch_pr_info(p2)\n",
    "    \n",
    "    #print(file_list1)\n",
    "    #print(file_list2)\n",
    "    \n",
    "    li1 = []\n",
    "    for file in file_list1:\n",
    "        li1.append(os.path.basename(file['name']))\n",
    "    \n",
    "    li2 = []\n",
    "    for file in file_list2:\n",
    "        li2.append(os.path.basename(file['name']))\n",
    "    \n",
    "    li = list(set(li1) & set(li2))\n",
    "    ps = [os.path.splitext(file)[0] for file in li]\n",
    "    \n",
    "    #ps = li\n",
    "    \n",
    "    ok = False\n",
    "    names = []\n",
    "    \n",
    "    s1 = set(p1['title'].lower().split())\n",
    "    s2 = set(p2['title'].lower().split())\n",
    "    s3 = s1 & s2\n",
    "    \n",
    "    for p in ps:\n",
    "        if (p.lower() in s1) or (p.lower() in s2):\n",
    "            ok = True\n",
    "            names.append(p)\n",
    "    \n",
    "    ok2 = False\n",
    "    names2 = []\n",
    "    for p in ps:\n",
    "        if (p in p1['title']) and (p in p2['title']):\n",
    "            ok2 = True\n",
    "            names2.append(p)\n",
    "    \n",
    "    '''\n",
    "    if ok != ok2:\n",
    "        print(p1['title'])\n",
    "        print(p2['title'])\n",
    "        print(names)\n",
    "        print(names2)\n",
    "        print('-----')\n",
    "    '''\n",
    "    \n",
    "    if ok2:\n",
    "        num += 1\n",
    "\n",
    "    \n",
    "    if ok2:\n",
    "        print(p1['title'])\n",
    "        print(p2['title'])\n",
    "        print(names)\n",
    "        print('------')\n",
    "    \n",
    "    \n",
    "    #break\n",
    "\n",
    "print(num, tot, 1.0 * num / tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from git import *\n",
    "\n",
    "num = 0\n",
    "tot = 0\n",
    "tot2 = 0\n",
    "tot3 = 0\n",
    "totn = 0\n",
    "\n",
    "ff = open('data/msr_r.txt', 'w')\n",
    "\n",
    "with open('data/clf/msr_positive_pairs.txt') as f:\n",
    "    for t in f.readlines():\n",
    "        r, n1, n2 = t.strip().split()\n",
    "        \n",
    "        p1 = get_pull(r, n1)\n",
    "        p2 = get_pull(r, n2)\n",
    "        \n",
    "        if 'changed_files' in p1:\n",
    "            if p1['changed_files'] > 0:\n",
    "                tot += p1[\"additions\"]\n",
    "                tot2 += p1[\"deletions\"]\n",
    "                tot3 += p1[\"changed_files\"]\n",
    "                totn += 1\n",
    "                \n",
    "                print(p1[\"changed_files\"], p1[\"additions\"], p1[\"deletions\"], file=ff)\n",
    "        \n",
    "        if 'changed_files' in p2:\n",
    "            if p2['changed_files'] > 0:\n",
    "                tot += p2[\"additions\"]\n",
    "                tot2 += p2[\"deletions\"]\n",
    "                tot3 += p2[\"changed_files\"]\n",
    "                totn += 1\n",
    "                \n",
    "                print(p2[\"changed_files\"], p2[\"additions\"], p2[\"deletions\"], file=ff)\n",
    "        \n",
    "        '''\n",
    "        if check_too_big(p1) or check_too_big(p2):\n",
    "            print(t)\n",
    "            try:\n",
    "                print(p1[\"changed_files\"], p1[\"additions\"], p1[\"deletions\"])\n",
    "                print(p2[\"changed_files\"], p2[\"additions\"], p2[\"deletions\"])\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            print('-------')\n",
    "            num += 1\n",
    "        '''\n",
    "\n",
    "print(1.0 * tot / totn)\n",
    "print(1.0 * tot2 / totn)\n",
    "print(1.0 * tot3 / totn)\n",
    "\n",
    "print(totn)\n",
    "ff.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#file = 'data/clf/msr_positive_pairs_feature_vector_text_lsi_code_tfidf_ori_and_overlap_X_and_Y.txt'\n",
    "#file = 'data/clf/rly_false_pairs_feature_vector_text_tfidf_code_tfidf_ori_and_overlap_X_and_Y.txt'\n",
    "file = 'data/clf/first_nn.txt'\n",
    "\n",
    "from git import *\n",
    "\n",
    "# from clf import *\n",
    "\n",
    "# c = classify()\n",
    "\n",
    "total, num = 0, 0\n",
    "\n",
    "\n",
    "vets = []\n",
    "\n",
    "with open(file) as f:\n",
    "    for t in f.readlines():\n",
    "        v = t.replace('[','').replace(']','').replace(',','').split()\n",
    "        r, n1, n2 = v[0], v[1], v[2]\n",
    "        label = v[-1]\n",
    "        try:\n",
    "            vet = [float(x) for x in v[3:-1]]\n",
    "        except:\n",
    "            print('error', t)\n",
    "            \n",
    "        vets.append(vet)\n",
    "\n",
    "        '''\n",
    "        if check_large(get_pull(r, n1)) and check_large(get_pull(r, n2)):\n",
    "            total += c.predict_proba([vet])[0][1]\n",
    "            num += 1\n",
    "        '''\n",
    "\n",
    "from numpy import array\n",
    "\n",
    "vets = array(vets)\n",
    "\n",
    "for i in range(9):\n",
    "    l = len(vets[:,i])\n",
    "    print(1.0 * sum(vets[:,i]) / l)\n",
    "    \n",
    "for i in range(9):\n",
    "    print(max(vets[:,i]), min(vets[:,i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "def pp(p):\n",
    "    if check_large(p):\n",
    "        files = fetch_pr_info(p)\n",
    "        l = len(files)\n",
    "        \n",
    "        print(p['base']['repo']['full_name'], p['number'], l)\n",
    "        #print('---')\n",
    "'''\n",
    "\n",
    "from git import *\n",
    "from comp import *\n",
    "from clf import *\n",
    "\n",
    "cnt = 0\n",
    "with open('data/clf/first_nondup.txt') as f:\n",
    "    for t in f.readlines():\n",
    "        r, n1, n2 = t.strip().split()\n",
    "        \n",
    "        if not (r == 'kubernetes/kubernetes'):\n",
    "            continue\n",
    "            \n",
    "        p1 = get_pull(r, n1)\n",
    "        p2 = get_pull(r, n2)\n",
    "        \n",
    "        t = get_pr_sim_vector(p1, p2)\n",
    "        \n",
    "        cnt += 1\n",
    "        \n",
    "        if cnt % 10 == 0:\n",
    "            print(cnt)\n",
    "\n",
    "        '''\n",
    "        print(p1[\"additions\"], p2[\"additions\"], file=out)\n",
    "        \n",
    "        if check_large(p1) or check_large(p2):\n",
    "            print(t.strip())\n",
    "            #print(get_pr_sim(p1, p2)['code'])\n",
    "            #print(len(fetch_pr_info(p1)), len(fetch_pr_info(p2)))\n",
    "        '''\n",
    "        \n",
    "out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from git import *\n",
    "\n",
    "\n",
    "with open('data/clf/second_msr_pairs_nolarge.txt') as f:\n",
    "    for t in f.readlines():\n",
    "        r, n1, n2 = t.strip().split()\n",
    "        if n1 > n2:\n",
    "            n1, n2 = n2, n1\n",
    "        \n",
    "        p1 = get_pull(r, n1)\n",
    "        p2 = get_pull(r, n2)\n",
    "        \n",
    "        try:\n",
    "            print(p1[\"additions\"], p2[\"additions\"])\n",
    "        except:\n",
    "            print('error!', t)\n",
    "        '''\n",
    "        if check_large(p1) or check_large(p2):\n",
    "            print('error')\n",
    "            print(t)\n",
    "        ''' \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from git import *\n",
    "\n",
    "cnt = 0\n",
    "\n",
    "with open('data/clf/first_nondup.txt') as f:\n",
    "    for t in f.readlines():\n",
    "        r, n1, n2 = t.strip().split()\n",
    "        def check(r, n):\n",
    "            path = '/DATA/luyao/pr_data/%s/%s/raw_diff.json' % (r, n)\n",
    "            \n",
    "            fetch_file_list(get_pull(r, n))\n",
    "            \n",
    "            try:\n",
    "                t = os.path.getsize(path)\n",
    "            except:\n",
    "                t = 0\n",
    "            \n",
    "            '''\n",
    "            if t >= 50 * 1024:\n",
    "                print(r, n, 'size=', t)\n",
    "            '''\n",
    "            \n",
    "        check(r, n1)\n",
    "        check(r, n2)\n",
    "        \n",
    "        cnt += 1\n",
    "        if cnt % 1000 == 0:\n",
    "            print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from git import *\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# choose = ['cocos2d/cocos2d-x', 'dotnet/corefx', 'django/django', 'angular/angular.js', 'JuliaLang/julia', 'ceph/ceph', 'joomla/joomla-cms', 'facebook/react', 'hashicorp/terraform', 'rails/rails', 'docker/docker', 'elastic/elasticsearch', 'emberjs/ember.js', 'ansible/ansible']\n",
    "\n",
    "choose = ['facebook/react', 'moby/moby']\n",
    "\n",
    "for repo in choose:\n",
    "    print(repo)\n",
    "    cnt = 0\n",
    "    nums = os.listdir('/DATA/luyao/pr_data/%s' % repo)\n",
    "    # nums = shuffle(nums)[:1000]\n",
    "    for num in nums:\n",
    "        cnt += 1\n",
    "        if cnt % 100 == 0:\n",
    "            print(cnt)\n",
    "        if num.isdigit():\n",
    "            if not os.path.exists('/DATA/luyao/pr_data/%s/%s/parse_diff.json' % (repo, num)):\n",
    "                p = get_pull(repo, num)\n",
    "                if not check_large(p):\n",
    "                    len_f = len(fetch_pr_info(p))\n",
    "\n",
    "\n",
    "import os\n",
    "from git import *\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# choose = ['cocos2d/cocos2d-x', 'dotnet/corefx', 'django/django', 'angular/angular.js', 'JuliaLang/julia', 'ceph/ceph', 'joomla/joomla-cms', 'facebook/react', 'hashicorp/terraform', 'rails/rails', 'docker/docker', 'elastic/elasticsearch', 'emberjs/ember.js', 'ansible/ansible']\n",
    "\n",
    "# choose = ['elastic/elasticsearch', 'emberjs/ember.js', 'ansible/ansible']\n",
    "\n",
    "choose = ['moby/moby']\n",
    "\n",
    "for repo in choose:\n",
    "    print(repo)\n",
    "    cnt = 0\n",
    "    nums = os.listdir('/DATA/luyao/pr_data/%s' % repo)\n",
    "    nums = shuffle(nums)[:5000]\n",
    "    for num in nums:\n",
    "        cnt += 1\n",
    "        if cnt % 100 == 0:\n",
    "            print(cnt)\n",
    "        if num.isdigit():\n",
    "            if not os.path.exists('/DATA/luyao/pr_data/%s/%s/parse_diff.json' % (repo, num)):\n",
    "                p = get_pull(repo, num)\n",
    "                if not check_too_big(p):\n",
    "                    print(repo, num)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from git import *\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "file = 'data/clf/msr_positive_pairs.txt'\n",
    "\n",
    "def get_time(t):\n",
    "    return datetime.strptime(t, \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "\n",
    "def check(pull, pullA):\n",
    "    # same author\n",
    "    if pullA[\"user\"][\"id\"] == pull[\"user\"][\"id\"]:\n",
    "        return True\n",
    "\n",
    "    # case of following up work (not sure)\n",
    "    if str(pull[\"number\"]) in (get_pr_and_issue_numbers(pullA[\"title\"]) + \\\n",
    "                               get_pr_and_issue_numbers(pullA[\"body\"])):\n",
    "        return True\n",
    "    \n",
    "    if abs((get_time(pullA[\"updated_at\"]) - get_time(pull[\"updated_at\"])).days) >= 5 * 365: # more than 4 years\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "def c2(pull, pullA):\n",
    "    if (pull[\"merged_at\"] is not None) and \\\n",
    "            (get_time(pull[\"merged_at\"]) < get_time(pullA[\"created_at\"])) and \\\n",
    "            ((get_time(pullA[\"created_at\"]) - get_time(pull[\"merged_at\"])).days >= 14):\n",
    "        return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "num = 0\n",
    "for t in open(file).readlines():\n",
    "    tt = t.split()\n",
    "    r, n1, n2 = tt[0], tt[1], tt[2]\n",
    "    if n1 > n2:\n",
    "        n1, n2 = n2, n1\n",
    "\n",
    "    p1 = get_pull(r, n1)\n",
    "    p2 = get_pull(r, n2)\n",
    "    \n",
    "    # z = t.strip()\n",
    "    flag = 'False'\n",
    "    if c2(p1, p2):\n",
    "        z += \" True\"\n",
    "        num += 1\n",
    "        flag = 'True'\n",
    "        print(t.strip(), (get_time(p2[\"created_at\"]) - get_time(p1[\"merged_at\"])).days)\n",
    "    #print(flag)\n",
    "\n",
    "print(num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from git import *\n",
    "from detect import *\n",
    "\n",
    "with open('data/clf/msr_positive_pairs.txt') as f:\n",
    "    for t in f.readlines():\n",
    "        r, n1, n2 = t.strip().split()\n",
    "        if n1 > n2:\n",
    "            n1, n2 = n2, n1\n",
    "        \n",
    "        p1 = get_pull(r, n1)\n",
    "        p2 = get_pull(r, n2)\n",
    "        \n",
    "        if check_pro_pick(p1, p2):\n",
    "            print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
